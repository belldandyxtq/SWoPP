\section{Related Work}
\label{sec:related_work}
Cloud computing is becoming a topic of much interest in recent years, not only famous Internet companies like google, Amazon, IBM, Oracle, Microsoft provide public cloud, many companies start to build or have built private cloud for internal computation. Recently hybrid cloud, which is a composition of two or more clouds (private or public) is becoming a hot topic since it allows a business to take advantage of the scalability and cost-effectiveness that a public cloud offers without exposing critical application and data to third-party vulnerabilties, also by using cloud bursting, a small private cloud can easily burst into a large cloud to deal with temporality request peak. 
Several rearch works have been done on hybrid cloud and cloud bursting, Tekin Bicer \emph{el at.}\cite{time_and_cost} considered a software framework to enable data-intensive computing with cloud bursting, which use a combination of compute resources from local cluster and a public cloud to proceesing on a geographically distributed data set.
Their framework assume computation nodes allocated in both local cluster and public cloud, and data set is geographically distributed, However in our study, data set is stored in local system and in order to obtain a high communication throughput between computation nodes, we assume that nodes used for the same job allocated in the same system.
Another cloud bursting application can be seen in Tian Guo\emph{el at.}\cite{Seagull}, they introduced a system called Seagull, designed to facilitate cloud brusting by determining which applications should be transitioned into the cloud and automating the movement process at the proper time. Their work focused on determine which applications should be moved to public cloud, and our work focus on the methdology of filling the I/O throughput in cloud bursting.

There are also several paper about data I/O throughput, transfering and data processing in hybrid cloud.
Chiba Tatsuhiro \emph{el at.}\cite{Chiba} proposed two high performance multicast algorithms used for transfering large amounts of data stored in Amazon S3 to multiple Amazon EC2 nodes.
Tekin Bicer \emph{el at.}\cite{MATE-EC2} also described a middleware that allows the specification of data processing using a high-level API in Amazon S3.
