\begin{abstract}
%Parallel programming are used to reduce execution time of complex problems, also fully utilizing computing resource of Supercomputers.

%supercomputers usually consist of a large number of nodes, provide high parallelism for multi-user.
%However computing nodes in supercomputers will not meet the request in some situation, such as some nodes have to be shut down to reduce electric consumption in summer or just several serial applications occupy nodes making others must wait.
%large serial applications will occupy computation nodes for a long time and causes some other applications which use numerous nodes to wait in a running queue, leads a low utilization of computing resource.
%One solution is running virtual machine on 
%In this paper, a comparison was made between a Public Cloud (AMAZON EC2) and a Supercomputer (TSUBAME) on Ethernet Performance and leading a 
%In order to satisfy these temporary request peak, we are trying to federate supercomputers with public cloud, which is known as cloud bursting.
%Although some sophisticated solutions are available, still we are facing several challenges, since there are a significant performance gap between supercomputers and public cloud.
%In this paper, we focus on I/O throughput between these two environments, we propose a I/O Bursting Buffer Model to burst I/O throughput between supercomputer and public cloud and reduce the cost for extra time usage caused by low I/O throughput.
%we also provide a simulation based on several benchmarks on TSUBAME supercomputer and AMAZON EC2 public cloud.
%The result shows our model can provide a stable and high I/O throughput as well as a low cost in most cases.

Extreme-scale HPC systems, which consist of a large number of compute nodes, can provide high computational capacity for multiple users. However, computing nodes in the systems occasionally can not meet the demand due to bursty job requests in short period times. In order to accommodate the bursty requests, we consider federating HPC systems with public clouds, which is known as cloud bursting. Although the federated systems can acquire virtually infinite computational power with cloud bursting, the QoS may not be guaranteed due to a significant performance gap between HPC systems and public clouds. The most critical problem is a gap in I/O performance. In this paper, we propose an I/O acceleration technique using distributed cloud bursting buffers. We also create the I/O performance model to explore the effectiveness. Our model-based simulations, which target the TSUBAME supercomputer for an HPC system, and AMAZON EC2 for a public cloud, show that the distributed cloud busting buffer can improve I/O throughput while reducing the cost.

\end{abstract}

\begin{keyword}
Supercomputer, Cloud, I/O Bursting Buffer Model
\end{keyword}

\maketitle

%1
\section{Introduction}
An increasing number of scientific applications are now running on Supercomputer for high performance computing nodes, large bandwidth and low latency interconnection environment, also a great number of processors for high scalability.
%Data size need to be processed grows rapidly these days, which is known as Big Data, people perfer to use supercomputer to analyze Big Data for it supports high parallelism.

%Multi-user can use supercomputer at the same by using batch queue system which manage nodes and job submission.
Although supercomputer can offer a high computational cpacity, there are some situations HPC system can not satisfy user's demands even there are still some idle nodes, consider there are 50 nodes available, a user submit a serial application use only one node for an hour, after that, a job using 50 nodes is submitted, and have to wait until previous job finished although there are 49 nodes remainning available.
%high parallel application runs faster on Supercomputer for fully usage of computing resource, but a serial application will occupy computing nodes for a long time causing other application must wait.
Another problem is the power problem in summer, in order to reduce power consumption, some nodes will be forced to be shut down, reducing numbers of nodes will make the first problem more serous.

One solution is federating supercomputer with a public cloud, moving parts of job and computation to public cloud when there are not enough computing nodes available for user's request, which is known as cloud bursting.
Although cloud bursting is used by several companies and already have some sophisticated solutions\cite{Eucalyptus,stratos,Seagull}, since there are a significant performance gap between supercomputer nodes and cloud nodes, there will still be several problems when we try to federate a supercomputer with a public cloud, and there are several studies on cloud burst about cost\cite{Seagull}, execution time\cite{time_and_cost}, etc..
The biggest problem will be data transfer throughput between two environment, supercomputers usual deal with Gigabyte or even Petabyte input and output of data, low I/O throughput will suffer supercomputer user. This paper focuses on methodology of increasing throughput when we do federation.

In order to increase data transfer throughput, we propose a I/O burst buffer architecture that uses several nodes in each system as a I/O nodes to achieve high throughput concurrent data transferring, and a I/O burst buffer model that uses to switch between I/O burst buffer mode and direct connect mode.
%This I/O bursting buffer architecture can be mainly used two situation, first in data I/O, the other one will be when there are some nodes need to migrate from a cloud to another cloud with snapshot, snapshots can be transferred without be stored to shared storage.
%Since, I/O bursting buffer needs three times data transfer, sometimes direct transfer will achieve a higher throughput, I/O bursting buffer model using a evaluation throughput using I/O bursting buffer and without I/O bursting buffer to determine I/O bursting buffer mode or direct connection mode.
Also, public cloud usually charges for nodes usage, using I/O bursting buffer may reduce the computation time, but I/O nodes will be charged for money, we also provide a cost-based model, to reduce the overall cost.

Our contribution can be summary as following:
\begin{itemize}
	\item An architecture of I/O burst buffer for increasing data transfer throughput between two systems.
	\item A throughput-based I/O burst buffer model uses to switch between I/O bursting mode and direct connection mode in order to achieve a high data transfer when federating two systems, a cost-based I/O burst buffer model uses to reduce the total cost and a queue model used.
	%\item 
	\item Evaluating I/O burst buffer architecture and two models by using data obtained from several benchmarks from TSUBAME supercomputer and AMAZON EC2 public cloud.
\end{itemize}
%2
The remainder of this paper is organized as follow:in section 2, the motivation and background of this study will be introduced, a overview of I/O bursting buffer Architecture including direct connection and I/O bursting buffer will be introduced in section 3, and the model used to switch between two modes will be described in section 4, a simulation result of our model %based on data obtained from several benchmark on TSUBAME V queue and AMAZON EC2 
will be shown in section 5, and finally, conclusion and related work will be seen in section 6.